Maze Game with Q-Learning
This project implements a Maze game using the Q-Learning reinforcement learning algorithm. An agent learns to navigate from a starting position to a goal while avoiding walls. The code is written in Python with Pygame and is compatible with Pyodide for browser execution.
Features

Environment: A 10x10 grid with fixed walls, an agent, and a goal.
Q-Learning:
State: Agent's current coordinates (x, y).
Actions: Up, down, left, right.
Rewards: +100 for reaching the goal, -10 for hitting walls, -1 for each valid move.
Parameters: Learning rate ($\alpha=0.1$), discount factor ($\gamma=0.9$), exploration rate ($\epsilon=0.1$).


Graphics: Agent (green), goal (red), walls (blue), and info display (score, episode, steps).
Execution: Uses a standard Pygame loop, compatible with Pyodide.

Prerequisites

Python 3.8+
Pygame (for local execution)
Pyodide (for browser execution)

How to Run

Download the maze_qlearning.py file.
For local execution:python maze_qlearning.py


For browser execution:
Run the code in an environment like JupyterLab with Pyodide support.
Alternatively, use a web server with Pyodide.



Observing Learning

In early episodes, the agent moves randomly due to exploration.
Over time, the agent learns to find shorter paths to the goal while avoiding walls.
Score, episode number, and step count are displayed in the top-left corner.

Possible Improvements

Gradually decrease $\epsilon$ to focus on exploitation.
Add dynamic walls for increased challenge.
Use Deep Q-Learning (DQN) for larger mazes.
Store and display the optimal path after learning.

Author
Generated by Grok (xAI) - Date: July 02, 2025
